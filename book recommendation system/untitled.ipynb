{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book Recommendation System\n",
    "\n",
    "The purpose of this project is to develop a machine learning-based book recommendation system that provides personalized book suggestions to users based on their preferences. By analyzing user ratings and book attributes, the system aims to predict which books a user is most likely to enjoy, enhancing their overall experience.\n",
    "\n",
    "To identify relevant book recommendations, the system utilizes cosine similarity, a method that measures the similarity between books. This technique compares the characteristics of books a user has shown interest in with those of other books, ensuring that the recommendations are closely aligned with the user’s taste.\n",
    "\n",
    "The required datasets for this project, including book details, user ratings, and other relevant attributes, are imported in the form of CSV files sourced from the Kaggle website. These datasets provide the foundation for building the recommendation model, which processes and analyzes the data to generate accurate book suggestions.\n",
    "\n",
    "This recommendation uses collaborative filtering which says that if users A and B liked book X and user B likes book Y also, then user A might also like book Y. This way, book Y can be recommended to user A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nishc\\AppData\\Local\\Temp\\ipykernel_23248\\1721587479.py:6: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('books.csv')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # python library for array creation and manipulation for data analysis\n",
    "import pandas as pd # python library for data manipulation and analysis received through CSV files\n",
    "\n",
    "# load the necessary CSV files as pandas dataframes\n",
    "\n",
    "books = pd.read_csv('books.csv')\n",
    "users = pd.read_csv('users.csv')\n",
    "ratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's view first 5 rows of all three CSV files to see if they were loaded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, new york, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2             stockton, new york, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's also check number of rows and columns in each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271360, 8)\n",
      "(1149780, 3)\n",
      "(278858, 3)\n"
     ]
    }
   ],
   "source": [
    "print(books.shape)\n",
    "print(ratings.shape)\n",
    "print(users.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe 'books' has 271360 rows and 8 columns\n",
    "dataframe 'ratings' has 1149780 rows and 3 columns\n",
    "dataframe 'users' has 278858 rows and 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check number of empty cells in each column of all three dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN                   0\n",
       "Book-Title             0\n",
       "Book-Author            2\n",
       "Year-Of-Publication    0\n",
       "Publisher              2\n",
       "Image-URL-S            0\n",
       "Image-URL-M            0\n",
       "Image-URL-L            3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User-ID        0\n",
       "ISBN           0\n",
       "Book-Rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User-ID          0\n",
       "Location         0\n",
       "Age         110762\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's check number of duplicate rows in all three dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(books.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(ratings.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(users.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we see that there are no duplicate dataframes in all the tree dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_with_name = ratings.merge(books,on='ISBN') # merges dataframes 'ratings' and 'books' based of value of column 'ISBN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rating_df = ratings_with_name.groupby('Book-Title').count()['Book-Rating'].reset_index() # create a pandas dataframe by grouping dataframe\n",
    "# 'ratings_with_name' by book titles and counting how many times each book was rated and use 'reset_index' function to create dataframe\n",
    "\n",
    "num_rating_df.rename(columns={'Book-Rating':'num_ratings'},inplace=True) # rename 'Book-Rating' to 'num_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do the same thing again but instead of count, we use mean/average as aggregate function\n",
    "avg_rating_df = ratings_with_name.groupby('Book-Title')['Book-Rating'].mean().reset_index()\n",
    "avg_rating_df.rename(columns={'Book-Rating':'avg_rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_df = num_rating_df.merge(avg_rating_df,on='Book-Title') # create a dataframe by merging both the dataframes we created on 'Book-Title' column.\n",
    "# This dataframe consists of book title, number of ratings and average ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_df = popular_df[popular_df['num_ratings'] >= 250].sort_values('avg_rating', ascending=False).head(50)\n",
    "# filters 'popular_df' such that it keeps 50 most loved books by first keeping books with more than 250 ratings\n",
    "# and then sorts the rows of these more than 250 ratings books in descending order so that book with best average ratings come first\n",
    "# finally only 50 of the rows we got are kept in 'popular_df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_df = popular_df.merge(books,on='Book-Title').drop_duplicates('Book-Title')[['Book-Title','Book-Author','Image-URL-M','num_ratings','avg_rating']]\n",
    "# removes duplicate rows for the same book title and keeps only the necessary columns which are book title, author, image of cover page, number of ratings and average ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ratings_with_name.groupby('User-ID').count()['Book-Rating'] > 200 # creates a pandas dataframe of User-ID and boolean flag\n",
    "# based on whether they rated more than 200 books (True) or not (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = x[x].index # returns User-ID of users from dataframe 'x' who rated more than 200 books ie value of boolean flag is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rating = ratings_with_name[ratings_with_name['User-ID'].isin(flag)] # creates a filtered dataframe of dataframe 'x'\n",
    "# which contains only User-ID and boolean flag True ie only users which have rated more than 200 books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = filtered_rating.groupby('Book-Title').count()['Book-Rating']>=50 # creates a filtered dataframe 'y' of dataframe 'filtered_rating'\n",
    "# containing book titles of books that have been rated by 50 or more users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_books = y[y].index # extracts book titles of books from dataframe 'y'\n",
    "# ie titles of books that have been rated by 50 or more users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ratings = filtered_rating[filtered_rating['Book-Title'].isin(famous_books)] # returns a dataframe which is filtered form of dataframe\n",
    "# 'filtered_rating'. This filtered dataframe consists of rows for which book title is of famous books ie rated by more than 50 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = final_ratings.pivot_table(index='Book-Title',columns='User-ID',values='Book-Rating') # creates a table whose first row is User-ID\n",
    "# first column is book titles and other matrix[x][y] is rating of book 'x' by user with User-ID 'y'\n",
    "# if value of a cell is 'NaN', it means that user with User-ID 'y' has not rated book with book title 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.fillna(0,inplace=True) # modifies table 'pt' such that cells having value 'NaN' is replaced by 0 ie rating becomes 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-ID                                             254     2276    2766    \\\n",
      "Book-Title                                                                   \n",
      "1984                                                   9.0     0.0     0.0   \n",
      "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
      "2nd Chance                                             0.0    10.0     0.0   \n",
      "4 Blondes                                              0.0     0.0     0.0   \n",
      "A Bend in the Road                                     0.0     0.0     7.0   \n",
      "...                                                    ...     ...     ...   \n",
      "Year of Wonders                                        0.0     0.0     0.0   \n",
      "You Belong To Me                                       0.0     0.0     0.0   \n",
      "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
      "Zoya                                                   0.0     0.0     0.0   \n",
      "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
      "\n",
      "User-ID                                             2977    3363    4017    \\\n",
      "Book-Title                                                                   \n",
      "1984                                                   0.0     0.0     0.0   \n",
      "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
      "2nd Chance                                             0.0     0.0     0.0   \n",
      "4 Blondes                                              0.0     0.0     0.0   \n",
      "A Bend in the Road                                     0.0     0.0     0.0   \n",
      "...                                                    ...     ...     ...   \n",
      "Year of Wonders                                        7.0     0.0     0.0   \n",
      "You Belong To Me                                       0.0     0.0     0.0   \n",
      "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
      "Zoya                                                   0.0     0.0     0.0   \n",
      "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
      "\n",
      "User-ID                                             4385    6251    6323    \\\n",
      "Book-Title                                                                   \n",
      "1984                                                   0.0     0.0     0.0   \n",
      "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
      "2nd Chance                                             0.0     0.0     0.0   \n",
      "4 Blondes                                              0.0     0.0     0.0   \n",
      "A Bend in the Road                                     0.0     0.0     0.0   \n",
      "...                                                    ...     ...     ...   \n",
      "Year of Wonders                                        0.0     0.0     0.0   \n",
      "You Belong To Me                                       0.0     0.0     0.0   \n",
      "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
      "Zoya                                                   0.0     0.0     0.0   \n",
      "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
      "\n",
      "User-ID                                             6543    ...  271705  \\\n",
      "Book-Title                                                  ...           \n",
      "1984                                                   0.0  ...    10.0   \n",
      "1st to Die: A Novel                                    9.0  ...     0.0   \n",
      "2nd Chance                                             0.0  ...     0.0   \n",
      "4 Blondes                                              0.0  ...     0.0   \n",
      "A Bend in the Road                                     0.0  ...     0.0   \n",
      "...                                                    ...  ...     ...   \n",
      "Year of Wonders                                        0.0  ...     0.0   \n",
      "You Belong To Me                                       0.0  ...     0.0   \n",
      "Zen and the Art of Motorcycle Maintenance: An I...     0.0  ...     0.0   \n",
      "Zoya                                                   0.0  ...     0.0   \n",
      "\\O\\\" Is for Outlaw\"                                    0.0  ...     0.0   \n",
      "\n",
      "User-ID                                             273979  274004  274061  \\\n",
      "Book-Title                                                                   \n",
      "1984                                                   0.0     0.0     0.0   \n",
      "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
      "2nd Chance                                             0.0     0.0     0.0   \n",
      "4 Blondes                                              0.0     0.0     0.0   \n",
      "A Bend in the Road                                     0.0     0.0     0.0   \n",
      "...                                                    ...     ...     ...   \n",
      "Year of Wonders                                        9.0     0.0     0.0   \n",
      "You Belong To Me                                       0.0     0.0     0.0   \n",
      "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
      "Zoya                                                   0.0     0.0     0.0   \n",
      "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
      "\n",
      "User-ID                                             274301  274308  275970  \\\n",
      "Book-Title                                                                   \n",
      "1984                                                   0.0     0.0     0.0   \n",
      "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
      "2nd Chance                                             0.0     0.0     0.0   \n",
      "4 Blondes                                              0.0     0.0     0.0   \n",
      "A Bend in the Road                                     0.0     0.0     0.0   \n",
      "...                                                    ...     ...     ...   \n",
      "Year of Wonders                                        0.0     0.0     0.0   \n",
      "You Belong To Me                                       0.0     0.0     0.0   \n",
      "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
      "Zoya                                                   0.0     0.0     0.0   \n",
      "\\O\\\" Is for Outlaw\"                                    8.0     0.0     0.0   \n",
      "\n",
      "User-ID                                             277427  277639  278418  \n",
      "Book-Title                                                                  \n",
      "1984                                                   0.0     0.0     0.0  \n",
      "1st to Die: A Novel                                    0.0     0.0     0.0  \n",
      "2nd Chance                                             0.0     0.0     0.0  \n",
      "4 Blondes                                              0.0     0.0     0.0  \n",
      "A Bend in the Road                                     0.0     0.0     0.0  \n",
      "...                                                    ...     ...     ...  \n",
      "Year of Wonders                                        0.0     0.0     0.0  \n",
      "You Belong To Me                                       0.0     0.0     0.0  \n",
      "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0  \n",
      "Zoya                                                   0.0     0.0     0.0  \n",
      "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0  \n",
      "\n",
      "[706 rows x 810 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pt) # checking the table formed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the table formed has 706 rows and 810 columns.\n",
    "\n",
    "now that we have got all the necessary data for making a recommendation system, we can start making one using machine learning's cosine similarity algorithm though python's scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity # import the cosine similarity algorithm from sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = cosine_similarity(pt) # create cosine similarity matrix from table 'pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(706, 706)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores.shape # checking out the matrix formed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the matrix formed has 706 rows and 706 columns.\n",
    "\n",
    "now, create an actual function that will recommend books by taking name of a book as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(book_name):\n",
    "    # return co-ordinates of first occurece of given book name in table 'pt'\n",
    "    # then find 4 most similar books to it based on cosine similarity matrix values (excluding book given as input)\n",
    "    # sort them in descending order so that most similar book comes first\n",
    "    index = np.where(pt.index==book_name)[0][0]\n",
    "    similar_items = sorted(list(enumerate(similarity_scores[index])),key=lambda x:x[1],reverse=True)[1:5]\n",
    "    \n",
    "    data = [] # create an empty list in which similar books will be stored\n",
    "\n",
    "    for i in similar_items: # iterate through the 4 most similar books we found\n",
    "        item = [] # create an empty list in which necessary characteristics of similar books will be appended\n",
    "        \n",
    "        temp_df = books[books['Book-Title'] == pt.index[i[0]]] # find the similar books in the table 'pt'\n",
    "        \n",
    "        # add book title, author name, and image URL to 'item' for each similar book\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))\n",
    "        \n",
    "        data.append(item) # append the list formed to 'data' so 'data' is now a list of 'item' lists\n",
    "    \n",
    "    return data # return the 2D list formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Animal Farm',\n",
       "  'George Orwell',\n",
       "  'http://images.amazon.com/images/P/0451526341.01.MZZZZZZZ.jpg'],\n",
       " [\"The Handmaid's Tale\",\n",
       "  'Margaret Atwood',\n",
       "  'http://images.amazon.com/images/P/0449212602.01.MZZZZZZZ.jpg'],\n",
       " ['Brave New World',\n",
       "  'Aldous Huxley',\n",
       "  'http://images.amazon.com/images/P/0060809833.01.MZZZZZZZ.jpg'],\n",
       " ['The Vampire Lestat (Vampire Chronicles, Book II)',\n",
       "  'ANNE RICE',\n",
       "  'http://images.amazon.com/images/P/0345313860.01.MZZZZZZZ.jpg']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('1984') # testing the 'recommend' function by checking it with book titled '1984'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle module to store dataframe 'popular_df' as a byte stream for light easy and fast data retrieval\n",
    "import pickle\n",
    "pickle.dump(popular_df,open('popular.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271354</th>\n",
       "      <td>0449906736</td>\n",
       "      <td>Flashpoints: Promise and Peril in a New World</td>\n",
       "      <td>Robin Wright</td>\n",
       "      <td>1993</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0449906736.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449906736.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449906736.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271356</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271357</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271358</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271359</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242135 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                         Book-Title  \\\n",
       "0       0195153448                                Classical Mythology   \n",
       "1       0002005018                                       Clara Callan   \n",
       "2       0060973129                               Decision in Normandy   \n",
       "3       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4       0393045218                             The Mummies of Urumchi   \n",
       "...            ...                                                ...   \n",
       "271354  0449906736      Flashpoints: Promise and Peril in a New World   \n",
       "271356  0525447644                            From One to One Hundred   \n",
       "271357  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271358  0192126040                        Republic (World's Classics)   \n",
       "271359  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                 Book-Author Year-Of-Publication  \\\n",
       "0         Mark P. O. Morford                2002   \n",
       "1       Richard Bruce Wright                2001   \n",
       "2               Carlo D'Este                1991   \n",
       "3           Gina Bari Kolata                1999   \n",
       "4            E. J. W. Barber                1999   \n",
       "...                      ...                 ...   \n",
       "271354          Robin Wright                1993   \n",
       "271356            Teri Sloat                1991   \n",
       "271357      Christine Wicker                2004   \n",
       "271358                 Plato                1996   \n",
       "271359   Christopher  Biffle                2000   \n",
       "\n",
       "                                               Publisher  \\\n",
       "0                                Oxford University Press   \n",
       "1                                  HarperFlamingo Canada   \n",
       "2                                        HarperPerennial   \n",
       "3                                   Farrar Straus Giroux   \n",
       "4                             W. W. Norton &amp; Company   \n",
       "...                                                  ...   \n",
       "271354                                  Ballantine Books   \n",
       "271356                                      Dutton Books   \n",
       "271357                                HarperSanFrancisco   \n",
       "271358                           Oxford University Press   \n",
       "271359  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271354  http://images.amazon.com/images/P/0449906736.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271354  http://images.amazon.com/images/P/0449906736.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "0       http://images.amazon.com/images/P/0195153448.0...  \n",
       "1       http://images.amazon.com/images/P/0002005018.0...  \n",
       "2       http://images.amazon.com/images/P/0060973129.0...  \n",
       "3       http://images.amazon.com/images/P/0374157065.0...  \n",
       "4       http://images.amazon.com/images/P/0393045218.0...  \n",
       "...                                                   ...  \n",
       "271354  http://images.amazon.com/images/P/0449906736.0...  \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...  \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...  \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...  \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...  \n",
       "\n",
       "[242135 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.drop_duplicates('Book-Title') # drop duplicate rows for same book title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store pivot table 'pt', CSV file 'books', and cosine similarity table as byte stream\n",
    "pickle.dump(pt,open('pt.pkl','wb'))\n",
    "pickle.dump(books,open('books.pkl','wb'))\n",
    "pickle.dump(similarity_scores,open('similarity_scores.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
